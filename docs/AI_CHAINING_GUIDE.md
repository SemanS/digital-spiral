# AI Chaining Guide - Re≈•azenie √∫loh s AI

Tento dokument vysvetƒæuje ako re≈•azi≈• √∫lohy s AI asistentom a ak√© mo≈ænosti m√°≈°.

## üéØ ƒåo je re≈•azenie √∫loh?

**Re≈•azenie √∫loh** (task chaining) znamen√° ≈æe AI asistent m√¥≈æe vykona≈• viacero akci√≠ za sebou, priƒçom v√Ωsledok jednej akcie pou≈æije ako vstup pre ƒèal≈°iu.

**Pr√≠klad:**
```
Pou≈æ√≠vateƒæ: "N√°jdi v≈°etky open issues v projekte SCRUM a prirad ich pou≈æ√≠vateƒæovi John"
```

AI asistent:
1. **Vyhƒæad√° issues** pomocou `search_issues` s JQL: `project = SCRUM AND status = Open`
2. **Pre ka≈æd√© issue** zavol√° `assign_issue` s `assignee = john`
3. **Vr√°ti s√∫hrn** koƒæko issues bolo priraden√Ωch

---

## üîß Ako to funguje v na≈°om syst√©me?

### 1. **Function Calling (OpenAI / Google AI)**

N√°≈° syst√©m pou≈æ√≠va **Function Calling** - AI model rozhodne ktor√© funkcie zavola≈• a v akom porad√≠.

**Architekt√∫ra:**
```
User Prompt
    ‚Üì
AI Provider (Google AI / OpenAI)
    ‚Üì
Function Calls (tool_calls)
    ‚Üì
MCP Executor
    ‚Üì
Jira Adapter
    ‚Üì
Jira API
```

**K√≥d:**
```python
# orchestrator/ai_assistant_api.py

# 1. User prompt
response = await provider.chat(
    messages=messages,
    tools=MCP_TOOLS,
    system_message=system_message
)

# 2. Check if AI wants to call tools
if response.get("tool_calls"):
    tool_results = []
    
    # 3. Execute each tool call
    for tool_call in response["tool_calls"]:
        function_name = tool_call["function_name"]
        function_args = tool_call["arguments"]
        
        # 4. Execute MCP action
        result = await execute_mcp_action(function_name, function_args, tenant_id)
        
        tool_results.append({
            "tool_call_id": tool_call["tool_call_id"],
            "function_name": function_name,
            "result": result
        })
    
    return {
        "message": response["message"],
        "tool_calls": tool_results
    }
```

### 2. **Multi-step Chaining**

Ak chce≈° aby AI vykonalo viacero krokov za sebou, mus√≠≈°:

**Variant A: Single-turn (jednoduch√Ω)**
- AI rozhodne o v≈°etk√Ωch krokoch naraz
- Vykon√° v≈°etky tool calls v jednom requeste
- **V√Ωhoda:** R√Ωchle
- **Nev√Ωhoda:** Nem√¥≈æe reagova≈• na v√Ωsledky predch√°dzaj√∫cich krokov

**Variant B: Multi-turn (pokroƒçil√Ω)**
- AI vykon√° prv√Ω krok
- V√Ωsledok sa prid√° do konverz√°cie
- AI rozhodne o ƒèal≈°om kroku na z√°klade v√Ωsledku
- **V√Ωhoda:** Flexibiln√©, m√¥≈æe reagova≈• na v√Ωsledky
- **Nev√Ωhoda:** Pomal≈°ie (viac API calls)

**Pr√≠klad multi-turn:**
```python
# orchestrator/ai_assistant_api.py

# Turn 1: Search issues
response1 = await provider.chat(
    messages=[{"role": "user", "content": "N√°jdi open issues v SCRUM"}],
    tools=MCP_TOOLS
)

# Execute tool call
result1 = await execute_mcp_action("search_issues", {"jql": "project = SCRUM AND status = Open"})

# Turn 2: Assign issues based on search results
messages.append({"role": "assistant", "content": f"Na≈°iel som {len(result1['issues'])} issues."})
messages.append({"role": "user", "content": "Prirad ich v≈°etky Johnovi"})

response2 = await provider.chat(
    messages=messages,
    tools=MCP_TOOLS
)

# Execute tool calls for each issue
for issue in result1['issues']:
    await execute_mcp_action("assign_issue", {"issue_key": issue['key'], "assignee": "john"})
```

---

## üöÄ LangChain vs. N√°≈° syst√©m

### **N√°≈° syst√©m (Function Calling)**

**V√Ωhody:**
- ‚úÖ Jednoduch√Ω, priamy pr√≠stup
- ‚úÖ ≈Ωiadne extra dependencies
- ‚úÖ Funguje s Google AI aj OpenAI
- ‚úÖ R√Ωchle prototypovanie

**Nev√Ωhody:**
- ‚ùå Mus√≠≈° manu√°lne implementova≈• multi-turn chaining
- ‚ùå ≈Ωiadne built-in memory management
- ‚ùå ≈Ωiadne built-in error handling pre chains

### **LangChain**

**V√Ωhody:**
- ‚úÖ Built-in chaining patterns (Sequential, Parallel, Conditional)
- ‚úÖ Memory management (ConversationBufferMemory, etc.)
- ‚úÖ Error handling a retry logic
- ‚úÖ Veƒæa ready-made tools a integrations
- ‚úÖ Agents ktor√© m√¥≈æu rozhodova≈• o krokoch

**Nev√Ωhody:**
- ‚ùå Extra dependency (veƒæk√° kni≈ænica)
- ‚ùå Strm≈°ia learning curve
- ‚ùå Niekedy over-engineered pre jednoduch√© use cases

---

## üìö Kedy pou≈æi≈• LangChain?

### **Pou≈æi≈• LangChain ak:**

1. **Potrebuje≈° komplexn√© chains:**
   ```python
   from langchain.chains import SequentialChain
   
   # Chain 1: Search issues
   search_chain = LLMChain(llm=llm, prompt=search_prompt)
   
   # Chain 2: Analyze issues
   analyze_chain = LLMChain(llm=llm, prompt=analyze_prompt)
   
   # Chain 3: Assign issues
   assign_chain = LLMChain(llm=llm, prompt=assign_prompt)
   
   # Sequential chain
   overall_chain = SequentialChain(
       chains=[search_chain, analyze_chain, assign_chain],
       input_variables=["project_key"],
       output_variables=["assigned_issues"]
   )
   ```

2. **Potrebuje≈° memory management:**
   ```python
   from langchain.memory import ConversationBufferMemory
   
   memory = ConversationBufferMemory()
   
   # Conversation history sa automaticky uklad√°
   chain = ConversationChain(llm=llm, memory=memory)
   ```

3. **Potrebuje≈° agents:**
   ```python
   from langchain.agents import initialize_agent, Tool
   
   tools = [
       Tool(name="Search", func=search_issues, description="Search Jira issues"),
       Tool(name="Assign", func=assign_issue, description="Assign issue to user"),
   ]
   
   agent = initialize_agent(tools, llm, agent="zero-shot-react-description")
   agent.run("Find all open issues and assign them to John")
   ```

### **Nepou≈æ√≠va≈• LangChain ak:**

1. **M√°≈° jednoduch√© use cases** - Function calling staƒç√≠
2. **Chce≈° minim√°lne dependencies** - N√°≈° syst√©m je lightweight
3. **Potrebuje≈° r√Ωchle prototypovanie** - Function calling je r√Ωchlej≈°√≠

---

## üé® Pr√≠klady re≈•azenia v na≈°om syst√©me

### **Pr√≠klad 1: Sequential chaining (jednoduch√Ω)**

```python
# User: "N√°jdi v≈°etky open issues v SCRUM a prirad ich Johnovi"

# AI rozhodne o krokoch:
# 1. search_issues(jql="project = SCRUM AND status = Open")
# 2. assign_issue(issue_key="SCRUM-1", assignee="john")
# 3. assign_issue(issue_key="SCRUM-2", assignee="john")
# ...

# N√°≈° syst√©m vykon√° v≈°etky tool calls za sebou
```

### **Pr√≠klad 2: Conditional chaining (pokroƒçil√Ω)**

```python
# User: "N√°jdi v≈°etky high priority issues a ak je ich viac ako 10, prirad ich Johnovi"

# Turn 1: Search
response1 = await provider.chat(
    messages=[{"role": "user", "content": "N√°jdi v≈°etky high priority issues v SCRUM"}],
    tools=MCP_TOOLS
)

# Execute search
result1 = await execute_mcp_action("search_issues", {"jql": "project = SCRUM AND priority = High"})

# Turn 2: Conditional logic
if len(result1['issues']) > 10:
    messages.append({"role": "assistant", "content": f"Na≈°iel som {len(result1['issues'])} issues."})
    messages.append({"role": "user", "content": "Prirad ich v≈°etky Johnovi"})
    
    response2 = await provider.chat(messages=messages, tools=MCP_TOOLS)
    
    # Execute assignments
    for issue in result1['issues']:
        await execute_mcp_action("assign_issue", {"issue_key": issue['key'], "assignee": "john"})
```

### **Pr√≠klad 3: Parallel chaining**

```python
# User: "Pridaj koment√°r do SCRUM-1, SCRUM-2 a SCRUM-3"

# AI rozhodne o paraleln√Ωch tool calls:
tool_calls = [
    {"function_name": "add_comment", "arguments": {"issue_key": "SCRUM-1", "comment": "..."}},
    {"function_name": "add_comment", "arguments": {"issue_key": "SCRUM-2", "comment": "..."}},
    {"function_name": "add_comment", "arguments": {"issue_key": "SCRUM-3", "comment": "..."}},
]

# Execute all in parallel
import asyncio
results = await asyncio.gather(*[
    execute_mcp_action(tc["function_name"], tc["arguments"], tenant_id)
    for tc in tool_calls
])
```

---

## üîÆ Bud√∫ce roz≈°√≠renia

### **1. LangChain integr√°cia (optional)**

Ak by si chcel prida≈• LangChain:

```python
# orchestrator/ai_langchain.py

from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain.memory import ConversationBufferMemory

def create_jira_agent(tenant_id: str):
    """Create LangChain agent for Jira."""
    
    # Define tools
    tools = [
        Tool(
            name="search_issues",
            func=lambda jql: execute_mcp_action("search_issues", {"jql": jql}, tenant_id),
            description="Search Jira issues using JQL"
        ),
        Tool(
            name="add_comment",
            func=lambda issue_key, comment: execute_mcp_action("add_comment", {"issue_key": issue_key, "comment": comment}, tenant_id),
            description="Add comment to Jira issue"
        ),
        # ... more tools
    ]
    
    # Create agent
    llm = ChatOpenAI(temperature=0)
    memory = ConversationBufferMemory(memory_key="chat_history")
    
    agent = initialize_agent(
        tools,
        llm,
        agent="conversational-react-description",
        memory=memory,
        verbose=True
    )
    
    return agent

# Usage
agent = create_jira_agent("demo")
result = agent.run("Find all open issues in SCRUM and assign them to John")
```

### **2. Custom chaining patterns**

```python
# orchestrator/ai_chains.py

class JiraChain:
    """Custom chaining for Jira operations."""
    
    def __init__(self, provider, tenant_id):
        self.provider = provider
        self.tenant_id = tenant_id
        self.history = []
    
    async def run(self, prompt: str):
        """Run chain with automatic multi-turn."""
        
        messages = [{"role": "user", "content": prompt}]
        max_turns = 5
        
        for turn in range(max_turns):
            response = await self.provider.chat(messages, MCP_TOOLS)
            
            if not response.get("tool_calls"):
                # No more tool calls, return final response
                return response["message"]
            
            # Execute tool calls
            for tool_call in response["tool_calls"]:
                result = await execute_mcp_action(
                    tool_call["function_name"],
                    tool_call["arguments"],
                    self.tenant_id
                )
                
                # Add result to history
                messages.append({
                    "role": "assistant",
                    "content": f"Executed {tool_call['function_name']}: {result}"
                })
            
            # Check if we should continue
            messages.append({
                "role": "user",
                "content": "Continue if needed, otherwise summarize results."
            })
        
        return "Max turns reached"

# Usage
chain = JiraChain(provider, "demo")
result = await chain.run("Find all open issues and assign them to John")
```

---

## üìñ Odpor√∫ƒçania

### **Pre jednoduch√© use cases:**
- ‚úÖ Pou≈æi n√°≈° Function Calling syst√©m
- ‚úÖ Jednoduch√Ω, r√Ωchly, bez extra dependencies

### **Pre komplexn√© use cases:**
- ‚úÖ Zv√°≈æi≈• LangChain
- ‚úÖ Built-in patterns, memory, error handling
- ‚úÖ Agents pre automatick√© rozhodovanie

### **Pre custom logic:**
- ‚úÖ Implementuj vlastn√© chaining patterns
- ‚úÖ M√°≈° pln√∫ kontrolu nad flow
- ‚úÖ M√¥≈æe≈° kombinova≈• s LangChain

---

## üéØ Z√°ver

N√°≈° syst√©m pou≈æ√≠va **Function Calling** ktor√Ω je:
- ‚úÖ Jednoduch√Ω a priamy
- ‚úÖ Funguje s Google AI aj OpenAI
- ‚úÖ Dostatoƒçn√Ω pre v√§ƒç≈°inu use cases

Ak potrebuje≈° komplexnej≈°ie re≈•azenie, m√¥≈æe≈°:
1. **Implementova≈• vlastn√© chaining patterns** (odpor√∫ƒçam pre zaƒçiatok)
2. **Prida≈• LangChain** (ak potrebuje≈° advanced features)

**Odpor√∫ƒçanie:** Zaƒçni s Function Calling, pridaj LangChain len ak to naozaj potrebuje≈°.

---

**Vytvoril:** AI Assistant  
**D√°tum:** 2025-01-03  
**Verzia:** 1.0.0

